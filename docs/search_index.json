[
["index.html", "Algoritmos para el Análisis de Datos Fisiológicos Capítulo 1 Introducción", " Algoritmos para el Análisis de Datos Fisiológicos Gener Avilés R 2017-11-21 Capítulo 1 Introducción Éste curso es impartido en la Maestría y Doctorado en Ciencias e Ingeniería (MyDCI) de la Facultad de Ingeniería, Arquitectura y Diseño de la Universidad Autónoma de Baja California, campus Ensenada. El curso es impartido por la Dra. María de los Ángeles Cosío León. "],
["intro.html", "Capítulo 2 Conceptos Generales 2.1 Derivadas, derivadas parciales y sus implicaciones. 2.2 Funciones de Activación:", " Capítulo 2 Conceptos Generales 2.1 Derivadas, derivadas parciales y sus implicaciones. This methods tries to explain the correlation structure of a set of predictor variables using a smaller set o linear combinations of these variables called components, note that components are not variables, rather indicators of linear combinations between variables. Given a dataset with \\(m\\) variables a set of \\(k\\) linear combinations can be used to represent it (meaning that \\(k\\) contains almost as much information as the \\(m\\) variables), also \\(k&lt;&lt;m\\). 2.2 Funciones de Activación: 2.2.1 TanH TanHGener &lt;- function(x0){ (2/(1+exp(-2*x))-1) } x &lt;- seq(-5,5,.01) y &lt;- TanHGener(x) plot(x,y, main = &quot;Tangente Hiperbolica TanH&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 4) 2.2.2 Softsign softSignGener &lt;- function(x){ x/(1+abs(x)) } y1 &lt;- softSignGener(x) plot(x,y1, main = &quot;Softsign&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 4) 2.2.3 SoftPlus softPlusGener &lt;- function(x){ log(1+exp(x)) } y3 &lt;- softPlusGener(x) plot(x,y3, type = &quot;l&quot;, main = &quot;SoftPlus&quot;, col = &quot;red&quot;, lwd = 4) 2.2.4 SoftExponential softExpGener &lt;- function(a,x){ if (a &lt; 0){ -1*((log(1-a*(x+a)))/a) } else { if (a == 0){ x } else { ((exp(a*x)-1)/a)+a } } } y2 &lt;- softExpGener(-1,x) plot(x,y2, main = &quot;SoftExponential&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 4) 2.2.5 Sinusoid sinusoidalGener &lt;- function(x){ sin(x) } y4 &lt;- sinusoidalGener(x) plot(x,y4, type = &quot;l&quot;, main = &quot;Sinusoidal&quot;, col = &quot;red&quot;, lwd = 4) 2.2.6 Sinc sincGener &lt;- function(x){ xt&lt;-x xt[x==0]=1 xt[x!=0]=sin(x[x!=0])/x[x!=0] xt } y5 &lt;- sincGener(x) plot(x,y5, type = &quot;l&quot;, main = &quot;Sinc&quot;, col = &quot;red&quot;, lwd = 4) 2.2.7 Scaled exponential linear unit (SELU) seluGener &lt;- function(l,a,x){ xt&lt;-x xt[x&lt;0]=l*a*(exp(x[x&lt;0])-1) xt[x&gt;=0]=l*x[x&gt;=0] xt #if (x &lt; 0){ # l*a*(exp(x)-1) #} #else { # l * x #} } y6 &lt;- seluGener(1.0507, 1.67326,x) plot(x,y6, type = &quot;l&quot;, main = &quot;SELU&quot;, col = &quot;red&quot;, lwd = 4) 2.2.8 Rectified Linear Unit (ReLU) ReLUGener &lt;- function(x){ x[x&lt;0]=0 x } y8 &lt;- ReLUGener(x) plot(x,y8, main = &quot;ReLU&quot;, type = &quot;l&quot;, col = &quot;red&quot;, lwd = 4) 2.2.9 Randomized leaky rectified linear unit (RReLU) rreluGener &lt;- function(a,x){ xt&lt;-x xt[x&lt;0]=a*x[x&lt;0] xt } y9 &lt;- rreluGener(.5,x) plot(x,y9, main = &quot;RReLU&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.10 Parametric Rectified linear unit (PReLU) is just as RReLU 2.2.11 Logistic (a.k.a Soft Step) logisticGener &lt;- function(x){ 1/(1+exp(x)) } y10 &lt;- logisticGener(x) plot(x,y10, main = &quot;Logistic&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.12 Leaky rectified linear unit (Leaky ReLU) leakyReluGener &lt;- function(x){ xt&lt;-x xt[x&lt;0]=0.01*x[x&lt;0] xt } y11 &lt;- leakyReluGener(x) plot(x,y11, main = &quot;Leaky ReLU&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.13 Identity identityGener &lt;- function(x){ x } y12 &lt;- identityGener(x) plot(x,y12, main = &quot;Identity&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.14 Gaussian gaussianGener &lt;- function(x){ exp(-1*x^2) } y13 &lt;- gaussianGener(x) plot(x,y13, main = &quot;Gaussian&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.15 Exponential linear unit (ELU) eluGener &lt;- function(a,x){ xt&lt;-x xt[x&lt;0]=a*(exp(x[x&lt;0])-1) xt } y14 &lt;- eluGener(1,x) plot(x,y14, main = &quot;Exponential linear unit (ELU)&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.16 Binary Step binaryGener &lt;- function(x){ #temp1&lt;-x x[x&lt;=0]&lt;-0 x[x&gt;0]&lt;-1 x } y15 &lt;- binaryGener(x) plot(x,y15, main = &quot;Binary Step&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) 2.2.17 Bent identity bentGener &lt;- function(x){ (((sqrt(x^2+1)-1))+(2))+x } y16 &lt;- bentGener(x) plot(x,y16, main = &quot;Bent Identity&quot;, type = &quot;ln&quot;, col = &quot;red&quot;, lwd = 4) "],
["funciones-de-activacion-para-neuronas-en-redes-computacionales.html", "Capítulo 3 Funciones de Activación para Neuronas en Redes Computacionales", " Capítulo 3 Funciones de Activación para Neuronas en Redes Computacionales Name Plot Equation Derivative (with respect x) Range Order of Continuity Monotonic Derivative Monotonic Aproximates Identify Near the Origin TanH \\(f(x) = tanh(x) = \\frac{2}{1+e^2x}-1\\) \\(f&#39;(x) = 1 - f(x)^2\\) \\((-1,1)\\) \\(C^\\infty\\) Yes No Yes SoftSign \\(f(x)= \\frac{x}{1+|x|}\\) \\(f&#39;(x)=1-f(x)^2\\) \\((-1,1)\\) \\(C^1\\) Yes No Yes SoftPlus \\(\\displaystyle f(x)=\\ln(1+e^{x})\\) \\(\\displaystyle f&#39;(x)={\\frac {1}{1+e^{-x}}}\\) \\((0,\\infty)\\) \\(C^\\infty\\) Yes Yes No SoftExponential | | \\(f(\\alpha ,x) = \\left\\{{\\begin{array}{rcl}-{\\frac {\\ln(1-\\alpha (x+\\alpha ))}{\\alpha }}{\\mbox{ for }}\\alpha &lt; 0\\\\x{\\mbox{ for }}\\alpha =0\\\\{\\frac {e^{\\alpha x}-1}{\\alpha }}+\\alpha {\\mbox{ for }}\\alpha &gt; 0\\end{array}}\\right.\\) | \\(f&#39;(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}{\\frac {1}{1-\\alpha (\\alpha +x)}}{\\mbox{ for }}\\alpha &lt;0\\\\e^{\\alpha x}{\\mbox{ for }}\\alpha \\geq 0\\end{array}}\\right.\\) | \\((- \\infty,\\infty)\\) | \\(C^\\infty\\) | Yes | Yes | Yes iff \\(\\alpha = 0\\) | Sinusoid | | \\(f(x)=\\sin(x)\\) | \\(f&#39;(x)=\\cos(x)\\) | \\([-1,1]\\) | \\(C^\\infty\\) | No | No | Yes | Sinc | | \\(f(x)=\\left\\{{\\begin{array}{rcl}1{\\mbox{ for }}x=0\\\\{\\frac {\\sin(x)}{x}}{\\mbox{ for }}x\\neq 0\\end{array}}\\right.\\) | \\(f&#39;(x)=\\left\\{{\\begin{array}{rcl}0{\\mbox{ for }}x=0\\\\{\\frac {\\cos(x)}{x}}-{\\frac {\\sin(x)}{x^{2}}}{\\mbox{ for }}x\\neq 0\\end{array}}\\right.\\) | \\([\\approx -.217234,1]\\) | \\(C^\\infty\\) | No | No | No | Scaled exponential linear unit (SELU) | | \\(f(\\alpha ,x)=\\lambda \\left\\{{\\begin{array}{rcl}\\alpha (e^{x}-1){\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) \\(\\lambda =1.0507\\) y \\(\\alpha =1.67326\\) | \\(f&#39;(\\alpha ,x)=\\lambda \\left\\{{\\begin{array}{rcl}f(\\alpha ,x)+\\alpha {\\mbox{ for }}x&lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\((-\\lambda \\alpha,\\infty)\\) | \\(C^0\\) | Yes | No | No | Rectified linear unit (ReLU) | | \\(f(x)=\\left\\{{\\begin{array}{rcl}0{\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(f&#39;(x)=\\left\\{{\\begin{array}{rcl}0&amp;{\\mbox{for}}&amp;x&lt;0\\\\1&amp;{\\mbox{for}}&amp;x\\geq 0\\end{array}}\\right.\\) | \\([0,\\infty)\\) | \\(C^0\\) | Yes | Yes | No | Randomized leaky rectified linear unit (RReLU) | | \\(f(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}\\alpha x {\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(f&#39;(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}\\alpha {\\mbox{ for }}x&lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\((-\\infty, \\infty)\\) | \\(C^0\\) | Yes | Yes | No | Parametric rectified linear unit (PReLU) | | \\(f(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}\\alpha x{\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(f&#39;(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}\\alpha {\\mbox{ for }}x&lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\((-\\infty, \\infty)\\) | \\(C^0\\) | Yes iff \\(\\alpha \\geq 0\\) | Yes | Yes iff \\(\\alpha = 1\\) | Logistic (a.k.a soft step) | | \\(f(x)={\\frac {1}{1+e^{-x}}}\\) | \\(f&#39;(x)=f(x)(1-f(x))\\) | (0,1) | \\(C^\\infty\\) | Yes | No | No | Leaky rectified linear unit (Leaky ReLU) | | \\(f(x)=\\left\\{{\\begin{array}{rcl}0.01x{\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(f&#39;(x)=\\left\\{{\\begin{array}{rcl}0.01{\\mbox{ for }}x&lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\((-\\infty, \\infty)\\) | \\(C^0\\) | Yes | Yes | No | Identity | | \\(f(x) = x\\) | \\(f&#39;&#39;(x) = 1\\) | \\((-\\infty, \\infty)\\) | \\(C^\\infty\\) | Yes | Yes | Yes | Gaussian | | \\(f(x)=e^-x^2\\) | \\(f&#39;(x) = -2xe^-x^2\\) | \\((0,1]\\) | \\(C^\\infty\\) | No | No | No | Exponential linear unit (ELU) | | \\(f(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}\\alpha (e^{x}-1){\\mbox{ for }}x&lt;0\\\\x{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(f&#39;(\\alpha ,x)=\\left\\{{\\begin{array}{rcl}f(\\alpha ,x)+\\alpha {\\mbox{ for }}x&lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\((-\\alpha,\\infty)\\) | \\(C^1\\) when \\(\\alpha = 1\\), otherwise \\(C^0\\) | Yes iff \\(\\alpha \\geq 0\\) | Yes iff \\(0 \\leq \\alpha \\leq 1\\) | | Binary step | | \\(\\displaystyle f(x)=\\left\\{{\\begin{array}{rcl}0{\\mbox{ for }}x &lt;0\\\\1{\\mbox{ for }}x\\geq 0\\end{array}}\\right.\\) | \\(\\displaystyle f&#39;(x)=\\left\\{{\\begin{array}{rcl}0{\\mbox{ for }}x\\neq 0\\\\?{\\mbox{ for }}x=0\\end{array}}\\right.\\) | {0,1} | \\(C^{-1}\\) | Yes | No | No | Bent Identity | | \\(f(x)={\\frac {{\\sqrt {x^{2}+1}}-1}{2}}+x\\) | \\(f&#39;(x)={\\frac {x}{2{\\sqrt {x^{2}+1}}}}+1\\) | \\((-\\infty, \\infty)\\) | \\(C^\\infty\\) | Yes | Yes | Yes | ArcTan | | \\(f(x)=\\tan ^{-1}(x)\\) | \\(f&#39;(x)={\\frac {1}{x^{2}+1}}\\) | \\(\\left ( -\\frac{\\pi}{2},\\frac{\\pi}{2} \\right )\\) | \\(C^\\infty\\) | Yes | No | Yes | Adaptive piecewise linear (APL) | | \\(\\displaystyle f(x)=\\max(0,x)+\\sum _{s=1}^{S}a_{i}^{s}\\max(0,-x+b_{i}^{s})\\) | \\(\\displaystyle f&#39;(x)=H(x)-\\sum _{s=1}^{S}a_{i}^{s}H(-x+b_{i}^{s})\\) | \\((-\\infty, \\infty)\\) | \\(C^0\\) | No | No | No | S-shaped rectified linear activation unit (SReLU) | | $f_{t_{l},a_{l},t_{r},a_{r}}(x)={{\\begin{array}{rcl}t_{l}+a_{l}(x-t_{l}){}xt_{l}\\x {}t_{l} | | | | | | | "],
["experimentos-con-distintas-funciones-de-activacion.html", "Capítulo 4 Experimentos con Distintas Funciones de Activación 4.1 Funciones S-Shaped 4.2 Funciones V-Shaped", " Capítulo 4 Experimentos con Distintas Funciones de Activación Los siguientes ejercicios se realizaron con las fuciones de activación propuestas por Mirjalili and Lewis (2013), quienes propusieron una serie de funciones de activación para el algoritmo Binary Particle Swarm Optimization (BPSO). Los autores proponen 2 familias de funciones de activación, las llaman s-shaped y v-shaped: 4.1 Funciones S-Shaped 4.1.1 S1 \\[T(x) = \\frac{1}{1+e^{-2x}}\\] 4.1.2 S2 \\[T(x) = \\frac{1}{1+e^{-x}}\\] 4.1.3 S3 \\[T(x) = \\frac{1}{1+e^{(-x/2)}}\\] 4.1.4 S4 \\[T(x) = \\frac{1}{1+e^{(-x/3)}}\\] 4.2 Funciones V-Shaped 4.2.1 V1 \\[T(x)=\\left| erf(\\frac{\\sqrt{\\pi}}{2}) \\right| = \\left| \\frac{\\sqrt{\\pi}}{n} \\int_0^{(\\sqrt{\\pi}/2)^x}e^{t^2}dt \\right|\\] 4.2.2 V2 \\[T(x) = \\left| tanh(x) \\right|\\] 4.2.3 V3 \\[T(x) = \\left| \\frac{(x)}{\\sqrt{1+x^2}} \\right|\\] 4.2.4 V4 \\[T(x) = \\left| \\frac{2}{\\pi}arctan \\left( \\frac{\\pi}{2}x \\right) \\right|\\] 4.2.5 Visualización de Familia S-Shaped 4.2.6 Visualización de familia V-Shaped References "],
["programando-un-perceptron-por-las-piedritas.html", "Capítulo 5 Programando un Perceptrón Por las Piedritas 5.1 Base de datos para éste ejercicio 5.2 Preparación de los datos para uso del perceptrón 5.3 Implementación 5.4 Explorando resultados de \\(h_{\\theta}(x)\\)", " Capítulo 5 Programando un Perceptrón Por las Piedritas En éste ejercicio estaré buscando prorgamar un perceptrón con una función de activación logística. La estructura básica del perceptrón será como se muestra en la siguiente figura: La fórmula de la función de activación logística: \\[y = \\frac{1}{1+e^{-\\theta^{T} x}}\\] 5.1 Base de datos para éste ejercicio Estaré utilizando la base de datos Iris para éste ejercicio: head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Contiene 150 entradas con 4 features y 1 variable objetivo (especie de la planta). 5.2 Preparación de los datos para uso del perceptrón 5.2.1 Selección y preparacion de subconjunto de datos library(pracma) o &lt;- matrix(c(0.25,0.32,0.30,0.28), ncol = 4, nrow = 1) #pesos expresados como una matriz de 1x4. x &lt;-as.matrix(iris[,1:4]) #Conviertiendo los datos de Iris a matriz y excluyendo la variable objetivo. ot &lt;- t(o) 5.3 Implementación start.time &lt;- Sys.time() fun &lt;- function(o,x) { y &lt;- 1/(1+exp(x[,1:4] %*% t(o))) time.taken &lt;- Sys.time() - start.time {cat(&quot;Proceso terminado en: &quot;, time.taken, &quot;milisegundos.&quot;)} y } 5.4 Explorando resultados de \\(h_{\\theta}(x)\\) a &lt;- fun(o,x) #ejecutando la función con los datos de Iris. ## Proceso terminado en: 0.04801297 milisegundos. res &lt;- as.data.frame(cbind(a,iris[,5])) #data.frame que contiene los valores resultado de la función de activación del perceptrón y el valor de la variable objetivo en la base de datos Iris. 5.4.1 Resultados en tabla colnames(res) &lt;- c(&quot;Perceptrón&quot;, &quot;Etiqueta&quot;) head(res) ## Perceptrón Etiqueta ## 1 0.05360590 1 ## 2 0.06531426 1 ## 3 0.06629785 1 ## 4 0.06611239 1 ## 5 0.05325188 1 ## 6 0.03841999 1 5.4.2 Boxplots library(reshape2) library(ggplot2) testMelt &lt;- melt(res, id.var = &quot;Etiqueta&quot;) testMelt$Etiqueta &lt;- as.factor(testMelt$Etiqueta) g &lt;- ggplot(testMelt, aes(x = variable, y = value)) + geom_boxplot(aes(fill = Etiqueta)) + labs(title = &quot;Valores Provistos por Perceptrón por Etiqueta en Base de Datos IRIS&quot;, x = &quot;Valores&quot;, y = &quot;Grupos&quot;, caption = &quot;Valores obtenidos de un perceptrón con una función de activación logística.&quot;) g Derivado de éstas visualizaciones se decide tomar los siguientes valores como corte para la clasificación de los grupos: Etiqueta 1: \\(\\geq\\) 0.38 Etiqueta 2: &lt;0.038 &amp; &gt;=0.014 Etiqueta 3: \\(\\leq\\) 0.013 5.4.3 Clasificación con parámetros calculados Se realizará una clasificación de los resultados obtendios por el perceptrón en función a los valores indicados en el párrafo anterior, posteriormente éstos valores se asignarán a un vector clas que será agregado a la base de datos IRIS. clas&lt;-c() for(k in 1:dim(a)[1]){ if(a[k,1]&lt;=0.013) clas[k]&lt;-3 else if(a[k,1]&gt;0.013 &amp; a[k,1]&lt;=0.038) clas[k]&lt;-2 else clas[k]&lt;-1 } resTable&lt;-cbind.data.frame(iris,perceptron=a[,1],clasPercept = clas) perform &lt;- mean(as.numeric(resTable$Species)==resTable$clas) head(resTable) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species perceptron ## 1 5.1 3.5 1.4 0.2 setosa 0.05360590 ## 2 4.9 3.0 1.4 0.2 setosa 0.06531426 ## 3 4.7 3.2 1.3 0.2 setosa 0.06629785 ## 4 4.6 3.1 1.5 0.2 setosa 0.06611239 ## 5 5.0 3.6 1.4 0.2 setosa 0.05325188 ## 6 5.4 3.9 1.7 0.4 setosa 0.03841999 ## clasPercept ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 1 ## 6 1 5.4.4 Visualización de Clasificación colors &lt;- c(&quot;#3498DB&quot;, &quot;#F7DC6F&quot;, &quot;#82E0AA&quot;) resTable$clasPercept &lt;- as.factor(resTable$clasPercept) plot(resTable$perceptron, col = colors[resTable$clasPercept], pch = 19, xlab = &quot;Instancias&quot;, ylab = &quot;Valores&quot;, main = &quot;Clasificación Final por el Perceptrón&quot;) legend(&quot;topright&quot;, legend = c(&quot;Setosa&quot;,&quot;Versicolor&quot;, &quot;Virginica&quot;), fill = c(&quot;#3498DB&quot;, &quot;#F7DC6F&quot;, &quot;#82E0AA&quot;)) Con los resultados obtenidos en ésta tabla podemos apreciar que el perceptrón tiene un porcentaje de acierto de 0.88. "],
["distintas-funciones-de-activacion-en-un-perceptron.html", "Capítulo 6 Distintas Funciones de Activación en un Perceptrón 6.1 Datos a utilizar 6.2 Preparación de los datos para uso del perceptrón 6.3 Explorando resultados por función 6.4 Observaciones", " Capítulo 6 Distintas Funciones de Activación en un Perceptrón En éste ejercicio busco probar el rendimiento de un perceptrón al utilizar distintas funciones de activación. 6.1 Datos a utilizar Iris: datos numéricos de 3 diferentes familias de flores (longitud y anchura de sépalo y pétalo). PimaIndiansDiabetes: datos de la tribu Pima en EUA, con mediciones metabólicas clínicas y paraclínicas, con variable objetivo de diabético o no diabético. Sonar: Datos de estudios de Sonar en superficies rocósas y metálicas. A continuación se muestra un breve resumen de las tres bases de datos: 6.1.1 Iris Características distintivas: Valores mayores a 1 con excepción de la variable Petla.Width. Base de datos ampliamente utilizada para ejercicios de éste tipo. ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## 6.1.2 Pima Características distintivas: Contiene valores faltantes. Valores tienden a ser mayores a 1 por el orden de las decenas con excepción de la variable pregnant. ## pregnant glucose pressure triceps ## Min. : 0.000 Min. : 0.0 Min. : 0.00 Min. : 0.00 ## 1st Qu.: 1.000 1st Qu.: 97.0 1st Qu.: 62.00 1st Qu.: 0.00 ## Median : 3.500 Median :111.5 Median : 71.00 Median :23.00 ## Mean : 4.093 Mean :117.4 Mean : 68.72 Mean :19.57 ## 3rd Qu.: 7.000 3rd Qu.:138.8 3rd Qu.: 79.50 3rd Qu.:31.75 ## Max. :15.000 Max. :197.0 Max. :122.00 Max. :60.00 ## diabetes ## neg:97 ## pos:53 ## ## ## ## 6.1.3 Sonar Características distintivas: Valores entre 0 y 1. Valores generados por equipo electrónico. ## V1 V2 V3 V4 ## Min. :0.00250 Min. :0.00060 Min. :0.00240 Min. :0.00580 ## 1st Qu.:0.01360 1st Qu.:0.01638 1st Qu.:0.01963 1st Qu.:0.02455 ## Median :0.02370 Median :0.03285 Median :0.03650 Median :0.04445 ## Mean :0.03171 Mean :0.04274 Mean :0.04866 Mean :0.05924 ## 3rd Qu.:0.03855 3rd Qu.:0.05720 3rd Qu.:0.06380 3rd Qu.:0.08120 ## Max. :0.13710 Max. :0.23390 Max. :0.30590 Max. :0.42640 ## Class ## M:53 ## R:97 ## ## ## ## 6.2 Preparación de los datos para uso del perceptrón 6.2.1 Selección y preparacion de subconjunto de datos o &lt;- matrix(c(0.25,0.32,0.30,0.28), ncol = 4, nrow = 1) #pesos expresados como una matriz de 1x4. #o1 &lt;- matrix(c(1,1,1,1), ncol = 4, nrow = 1) ####### Conviertiendo los datos a matriz y excluyendo la variable objetivo. ############ #Iris irism &lt;-as.matrix(iris[,1:4]) #Pima pimam &lt;- as.matrix(pima[,1:4]) #Sonar sonarm &lt;- as.matrix(sonar[,1:4]) 6.3 Explorando resultados por función 6.3.1 Graficando las funciones Antes de realizar una aproximación a los datos, es importante explorar el comportamiento de cada función, a continuación se expresa de manera gráfica el comportamiento de ambas “familias”. Funciones S-Shaped S1: \\(\\frac{1}{1+e^{-2x}}\\) S2: \\(\\frac{1}{1+e^{-x}}\\) S3: \\(\\frac{1}{1+e^{(-x/2)}}\\) S4: \\(\\frac{1}{1+e^{(-x/3)}}\\) Funciones V-Shaped V1: \\(\\left| erf(\\frac{\\sqrt{\\pi}}{2}) \\right| = \\left| \\frac{\\sqrt{\\pi}}{n} \\int_0^{(\\sqrt{\\pi}/2)^x}e^{t^2}dt \\right|\\) v2: \\(\\left| tanh(x) \\right|\\) V3: \\(\\left| \\frac{(x)}{\\sqrt{1+x^2}} \\right|\\) v4: \\(\\left| \\frac{2}{\\pi}arctan \\left( \\frac{\\pi}{2}x \\right) \\right|\\) 6.3.2 Con los datos de Iris 6.3.3 Con los datos pima 6.3.4 Con los datos sonar 6.4 Observaciones Se puede apreciar que el rendimiento de las funciones de activación está relacionado con los tipos de datos que procese y su dinámica en particular. Ésto se vuelve obvio al observar los resultados anteriores. Otro punto igualmente importante es el ajuste de los pesos (valor \\(\\theta\\) en la fórmula general), en ésta aproximación se está utilizando un vector con números aleatorios entre \\(0\\) y \\(1\\) de longitud \\(n = 4\\). Una vez que el proceso de retropropagación se implemente, se esperaría que el rendimiento mejorar sustancialmente. 6.4.1 Modificación de los datos en función a las observaciones Derivado de las observaciones anteriores se decide exponer los datos de las tres bases de datos a algunas modificaciones para obtener corroborar los argumentos del párrafo anterior. A continuación se muestra los cambios realizados a los 4 valores feature de las bases de datos: \\(log_{10}(x[,1])\\) \\(\\sqrt{x[,2]}\\) \\(x[,3]^2\\) \\(x[,4]^{1/3}\\) 6.4.2 Visualización 6.4.2.1 Iris 6.4.2.2 pima 6.4.2.3 sonar "],
["red-neuronal-sin-retropropagacion.html", "Capítulo 7 Red Neuronal Sin Retropropagación 7.1 Cargando y preparando datos a utilizar 7.2 Preparando pesos 7.3 Construyendo la red 7.4 Capa de salida (1 perceptrón) 7.5 Visualización", " Capítulo 7 Red Neuronal Sin Retropropagación Para motivos de éste ejercicio se estará utilizando una estructura de red neuronal como lo indica la imagen que sigue: 7.1 Cargando y preparando datos a utilizar 7.2 Preparando pesos o0 &lt;-matrix(c(0.5,0.1,1,0.8,0.4,0.6,0.7,0.2), ncol = 8, nrow = 1) #o0 &lt;-matrix(c(0.25,0.32,0.30,0.28,0.26,0.35,0.30,0.22), ncol = 8, nrow = 1) o1 &lt;-matrix(o0[,-4:-9], nrow = 1, ncol = 3) o2 &lt;-matrix(o1[,-1], nrow = 1, ncol = 2) 7.3 Construyendo la red 7.3.1 Capa de acceso de los datos (3 perceptrones) Para ésta capa estaremos utilizando los pesos en la matríz \\(o0\\) y los valores proporcionados por la base de datos pima. source(&quot;funciones.R&quot;) ## 3.0 p1.1 &lt;- perceptron(pimam,o0,&quot;s2&quot;) p1.2 &lt;- perceptron(pimam,o0,&quot;s3&quot;) p1.3 &lt;- perceptron(pimam,o0,&quot;s4&quot;) red3.0 &lt;- matrix(c(as.vector(p1.1), as.vector(p1.2), as.vector(p1.3)), nrow = 768, ncol = 3) 7.3.2 Capa intermedia (2 perceptrones) Para ésta capa estaremos utilizando los pesos en la matriz \\(o1\\) y los valores en la matriz red3.0 producto de la capa de entrada de datos. library(pracma) ##3.1 p2.1 &lt;-perceptron(red3.0,o1,&quot;s1&quot;) p2.2 &lt;- perceptron(red3.0,o1,&quot;s2&quot;) red3.1 &lt;- matrix(c(as.vector(p2.1), as.vector(p2.2)), nrow = 768, ncol = 2) 7.4 Capa de salida (1 perceptrón) Para ésta capa estaremos utilizando los pesos en la matriz \\(o2\\) y los valores en la matriz red3.1, producto de la capa oculta en la red neuronal artificial. #3.2 p3.2 &lt;- perceptron(red3.1, o2, &quot;s4&quot;) 7.5 Visualización colors &lt;- c(&quot;#e5b020&quot;, &quot;#c9266a&quot;) resANN &lt;- as.data.frame(cbind(p3.2,pima[,9])) plot(resANN$V1, col = colors[resANN$V2], pch = 19, xlab = &quot;Instancias&quot;, ylab = &quot;Valores&quot;, main = &quot;Resultados Finales ANN&quot;) "],
["ejercicio-con-datos-cercanos-a-cero.html", "Capítulo 8 Ejercicio con Datos Cercanos a Cero 8.1 Base de datos para éste ejercicio 8.2 Preparación de los datos para uso del perceptrón 8.3 Explorando resultados por función", " Capítulo 8 Ejercicio con Datos Cercanos a Cero En éste ejercicio busco probar el rendimiento de funciones de activación V-Shaped con números cercanos a cero. 8.1 Base de datos para éste ejercicio Para éste ejercicio se estará utilizando la base de datos Sonar publicada por Gorman and Sejnowski (1988), quienes utilizaron redes neuronales artificiales para clasificar datos de sonares. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Contiene 150 entradas con 4 features y 1 variable objetivo (especie de la planta). 8.2 Preparación de los datos para uso del perceptrón 8.2.1 Selección y preparacion de subconjunto de datos library(pracma) o &lt;- matrix(c(0.25,0.32,0.30,0.28), ncol = 4, nrow = 1) #pesos expresados como una matriz de 1x4. x &lt;-as.matrix(iris[,1:4]) #Conviertiendo los datos de Iris a matriz y excluyendo la variable objetivo. ot &lt;- t(o) 8.3 Explorando resultados por función set.seed(123) source(&quot;funciones.R&quot;) perceptron&lt;-function(x,o,fun){ switch(fun, s1 = 1/(1+exp(x %*% (-2*t(o)))), s2 = 1/(1+exp(x %*% (-1*t(o)))), s3 = 1/(1+exp((x %*% (-1*t(o))))/2), s4 = 1/(1+exp((x %*% (-1*t(o)))/3)), v1 = abs(erf((sqrt(pi)/2)*x %*% t(o))), v2 = abs(tanh(x %*% t(o))), v3 = abs((x %*% t(o))/(sqrt(1+x^2 %*% t(o)))), v4 = abs((2/pi)*atan((pi/2)*x %*% t(o))) ) } a &lt;- perceptron(x,o,&quot;v4&quot;) #ejecutando la función con los datos de Iris. res &lt;- as.data.frame(cbind(a,iris[,5])) #data.frame que contiene los valores resultado de la función de activación del perceptrón y el valor de la variable objetivo en la base de datos Iris. colors &lt;- c(&quot;#3498DB&quot;, &quot;#F7DC6F&quot;, &quot;#82E0AA&quot;) res$V2 &lt;- as.factor(res$V2) plot(res$V1, col = colors[res$V2], pch = 19, xlab = &quot;Instancias&quot;, ylab = &quot;Valores&quot;, main = &quot;Clasificación Final por el Perceptrón&quot;) legend(&quot;bottomright&quot;, #inset = c(-0.2,0), legend = c(&quot;Setosa&quot;,&quot;Versicolor&quot;, &quot;Virginica&quot;), fill = c(&quot;#3498DB&quot;, &quot;#F7DC6F&quot;, &quot;#82E0AA&quot;)) 8.3.1 Boxplots library(reshape2) library(ggplot2) testMelt &lt;- melt(res, id.var = &quot;V2&quot;) testMelt$V2 &lt;- as.factor(testMelt$V2) g &lt;- ggplot(testMelt, aes(x = variable, y = value)) + geom_boxplot(aes(fill = V2)) + labs(title = &quot;Valores Provistos por Perceptrón por Etiqueta en Base de Datos IRIS&quot;, x = &quot;Valores&quot;, y = &quot;Grupos&quot;, caption = &quot;Valores obtenidos de un perceptrón con una función de activación logística.&quot;) g References "],
["bases-de-datos-medicas-de-interes-para-este-curso.html", "Capítulo 9 Bases de Datos Médicas de Interés para Éste Curso 9.1 Diabetes en Indios Pima 9.2 Heart Disease 9.3 Datos de Resonancias Magnéticas del cerebro", " Capítulo 9 Bases de Datos Médicas de Interés para Éste Curso 9.1 Diabetes en Indios Pima Originalmente del National Institute of Diabetes and Digestive and Kidney Disease, el producto final liberado para la comunidad de aprendizaje automatizado contiene únicamente instancias de mujeres de, por lo menos, 21 años de edad de la étnia PIMA americana. Las variables se pueden interpretar como sigue: pregnant: Número de embarazos tenidos. glucose: Concentración de glucosa en plasma a las 2 horas de iniciado un test de tolerancia a la glucosa. pressure: Presión arterial diastólica en mm/Hg triceps: Medición de pliegue cutáneo en región del tríceps en milímetros. insulin: Concentración sérica de insulina a las 2 horas de iniciado el test. mass: Índice de masa corporal calculado con la siguiente fórmula: \\(\\frac{peso \\space en \\space kg}{(altura \\space en \\space metros)^2}\\) pedigree age: Edad en años. diabetes: Variable objetivo indicando si el paciente tiene o no tiene diabetes. El objetivo de ésta base de datos es el ser utilizada para realizar predicciones de enfermedad con las variables predictoras proporcionadas a través de estadística computacional. 9.2 Heart Disease Generada entre doctores de centros médicos en Budapest, Suiza, y Cleveland. Ésta base de datos contiene en su totalidad 76 atributos, aunque los trabajos publicados que la mencionan han utilizado los 14 atributos provenientes de Cleveland. Los 14 atributos usados por otros autores son: age sex cp: tipo de dolor en el pecho Angina típica Agina atípica Dolor no anginoso Asintomático trestbps: presión arterial en reposo registrada en mm/Hg al ser admitido al hospital chol: colesterol sérico en mg/dl. fbs: glucosa sérica en ayuno &gt;120 mg/dl. 1 = verdadero, 2 = falso. restecg: Resultados del electrocardograma en reposo. 0 = normal 1 = anormalidades de onda T o segmento ST (inversiones o depresiones &gt;0.05mV) 2 = evidencia probable o definitiva de hipertrofia de ventrículo izquierdo por criterios de Estes. thalach: máxima frecuencia cardiaca alcanzada. exang: angina inducida por el ejercicio. 1 = Si, 2 = No) oldpeak: depresión del segmento ST en el ECG inducido por ejercicio en contraste a reposo. slope: pendiente del segmento ST en ECG durante ejercicio. Pendiente positiva (hacia arriba). Sin pendiente (plano). Pendiente negativa (hacia abajo). ca: número (0-3) de vasos mayores coloreados por fluoroscopía thal: 3 = normal. 6 = defecto estático. 7 = defecto reversible. num: Variable objetivo, diagnóstico de cardiopatía por angiografía. 0 = &lt;50% de estrechamiento de diámetro del vaso sanguíneo. 1 = &gt;50% de estrechamiento de diámetro del vaso sanguíneo. 9.3 Datos de Resonancias Magnéticas del cerebro library(oro.nifti) ## oro.nifti 0.7.2 ## ## Attaching package: &#39;oro.nifti&#39; ## The following object is masked from &#39;package:pracma&#39;: ## ## magic img &lt;- readNIfTI(&quot;data/Template-T1-U8-RALPFH-BR.nii.gz&quot;, reorient = FALSE) class(img) ## [1] &quot;nifti&quot; ## attr(,&quot;package&quot;) ## [1] &quot;oro.nifti&quot; dim(img) ## [1] 182 512 512 9.3.1 Visualizaciones iniciales 9.3.1.1 Todas las proyecciones image(img) 9.3.1.2 Visualizando el slice 225 image(img, z = 225, plot.type = &quot;single&quot;) 9.3.1.3 Proyecciones ortográficas orthographic(img) "]
]
